---
title: OpenAI-like와 함께 Droidrun 사용하기
---

이 가이드는 OpenAI 호환 API(OpenAI, Azure OpenAI, OpenRouter, LM Studio 등)와 함께 Droidrun 프레임워크를 사용하는 방법을 설명합니다. 이러한 LLM을 Droidrun과 통합하면 Android 기기를 자동화하고, 지능형 에이전트를 구축하며, OpenAI-like 엔드포인트를 사용하는 고급 워크플로를 실험할 수 있습니다.
## OpenAI-like란 무엇인가요?
"OpenAI-like"는 OpenAI REST API 표준을 구현하는 모든 API를 의미합니다. 여기에는 다음이 포함됩니다:
- **OpenAI** (api.openai.com)
- **Azure OpenAI**
- **OpenRouter** (https://openrouter.ai)
- **LM Studio** (로컬, https://lmstudio.ai)
- **OpenAI API를 모방하는 기타 로컬 또는 클라우드 엔드포인트**

> 📖 **OpenAI-like 심화 설명**
> 
> **정의**: OpenAI가 정의한 API 인터페이스 규격을 따르는 서비스들
> 
> **쉬운 비유**: USB 규격
> - USB 포트(OpenAI API 규격) = 표준 인터페이스
> - USB 기기들(다양한 프로바이더) = 같은 포트에 연결 가능
> - 삼성 충전기든 애플 충전기든 USB-C면 모두 사용 가능
> 
> **실제 작동 방식**:
> ```
> 요청 형식이 동일:
> POST /v1/chat/completions
> {
>   "model": "...",
>   "messages": [...]
> }
> 
> OpenAI든 OpenRouter든 같은 코드로 호출 가능!
> ```
> 
> **장점**:
> - ✅ 코드 재사용: OpenAI용 코드 → 다른 서비스에도 그대로 사용
> - ✅ 쉬운 마이그레이션: OpenAI → Claude로 api_base만 바꾸면 됨
> - ✅ 멀티 프로바이더: 여러 서비스를 동시에 사용 가능

## Droidrun과 함께 OpenAI-like를 사용하는 이유는?
- **유연성:** 클라우드 또는 로컬 LLM을 서로 교체하여 사용할 수 있습니다.
- **광범위한 모델 지원:** GPT-3.5, GPT-4 및 많은 커뮤니티 모델에 액세스할 수 있습니다.
- **쉬운 통합:** Droidrun은 OpenAI 호환 LLM을 기본적으로 지원합니다.

> 💡 **프로바이더별 특징 및 선택 가이드**
> 
> | 프로바이더 | 특징 | 장점 | 단점 | 권장 사용 케이스 |
> |-----------|------|------|------|-----------------|
> | **OpenAI** | 공식 GPT 모델 | 최고 성능, 안정적 | 비용 높음 | 프로덕션, 최고 품질 필요 시 |
> | **OpenRouter** | 100+ 모델 통합 | 다양한 선택, 가격 경쟁력 | 속도 약간 느림 | 모델 비교, 비용 절감 |
> | **Azure OpenAI** | MS 클라우드 | 엔터프라이즈 보안, SLA 보장 | 승인 필요, 비용 높음 | 기업용, 규제 산업 |
> | **LM Studio** | 로컬 실행 | 무료, 프라이버시, 오프라인 | 사양 필요, 성능 제한 | 개발/테스트, 민감 데이터 |
> 
> **실무 전략**:
> ```
> 개발 단계: LM Studio (무료 테스트)
>     ↓
> 프로토타입: OpenRouter (다양한 모델 실험)
>     ↓
> 프로덕션: OpenAI 또는 Azure (안정성)
> ```

## 사전 준비사항

- **Python 3.10+**
- 선택한 프로바이더의 **API 키** (예: OpenAI, OpenRouter, Azure 또는 로컬 서버)
- **droidrun** 프레임워크 설치 ([Droidrun 빠른 시작](../quickstart) 참조)

<Warning>
Droidrun Portal을 설정하고 활성화했는지 확인하세요.
</Warning>

## 1. API 키 설정하기

선택한 프로바이더의 API 키를 받으세요

> 🔑 **프로바이더별 API 키 발급 방법**
> 
> **OpenAI**:
> 1. [OpenAI Platform](https://platform.openai.com/api-keys) 방문
> 2. "Create new secret key" 클릭
> 3. 키 이름 지정 후 생성
> 4. `sk-` 로 시작하는 키 복사
> 
> **OpenRouter**:
> 1. [OpenRouter](https://openrouter.ai/keys) 로그인
> 2. "Create Key" 클릭
> 3. 무료 크레딧 제공 (신규 가입 시)
> 4. 키 복사 (여러 개 생성 가능)
> 
> **Azure OpenAI**:
> 1. Azure Portal에서 OpenAI 리소스 생성
> 2. "Keys and Endpoint" 메뉴에서 키 확인
> 3. API 키 + 엔드포인트 URL 모두 필요
> 4. 승인 절차 필요 (수일 소요 가능)
> 
> **LM Studio** (로컬):
> - API 키 불필요 (로컬 실행)
> - LM Studio 앱 실행 → "Local Server" 시작
> - `http://localhost:1234` 기본 주소

## 2. 필수 Python 패키지 설치하기

```sh
pip install 'droidrun[openai]'
```

## 3. 예시: OpenAI-like LLM과 함께 Droidrun 사용하기
다음은 OpenAI 호환 LLM 백엔드와 함께 Droidrun을 사용하는 최소 예시입니다:

```python
import asyncio
from llama_index.llms.openai_like import OpenAILike
from droidrun import DroidAgent, AdbTools

async def main():
    # 첫 번째로 연결된 기기의 adb 도구 로드
    tools = AdbTools()

    # OpenAI-like LLM 설정 (기본적으로 환경 변수에서 API 키와 base 사용)
    llm = OpenAILike(
        model="gpt-3.5-turbo",  # 또는 "gpt-4o", "gpt-4" 등
        api_base="http://localhost:1234/v1",  # 로컬 엔드포인트용
        is_chat_model=True, # droidrun은 채팅 모델 지원 필요
        api_key="YOUR API KEY"
    )

    # DroidAgent 생성
    agent = DroidAgent(
        goal="설정 앱 열고 배터리 잔량 확인하기",
        llm=llm,
        tools=tools,
        vision=False,        # 모델이 비전을 지원하면 True로 설정
        reasoning=False,     # 선택 사항: 계획/추론 활성화
    )

    # 에이전트 실행
    result = await agent.run()
    print(f"성공: {result['success']}")
    if result.get('output'):
        print(f"출력: {result['output']}")

if __name__ == "__main__":
    asyncio.run(main())
```

> 📖 **주요 파라미터 상세 설명**
> 
> **model** (모델명):
> - 프로바이더마다 다른 이름 사용
> - OpenAI: `gpt-4o`, `gpt-3.5-turbo`
> - OpenRouter: `openai/gpt-4`, `anthropic/claude-3.5-sonnet`
> - Azure: deployment 이름 (직접 설정한 이름)
> 
> **api_base** (API 엔드포인트):
> - 서비스의 기본 URL
> - OpenAI: `https://api.openai.com/v1` (기본값, 생략 가능)
> - OpenRouter: `https://openrouter.ai/api/v1`
> - LM Studio: `http://localhost:1234/v1`
> - Azure: `https://{your-resource}.openai.azure.com/`
> 
> **is_chat_model**:
> - `True`: 대화형 모델 (ChatGPT 스타일)
> - `False`: 완성형 모델 (GPT-3 스타일, 레거시)
> - Droidrun은 채팅 모델만 지원 → 항상 `True`
> 
> **api_key**:
> - 인증 키
> - 환경 변수 사용 권장: `os.getenv("OPENAI_API_KEY")`
> - 하드코딩 금지 (보안 위험)

### 로컬 및 대체 엔드포인트 팁

- **OpenRouter:** `api_base`를 `https://openrouter.ai/api/v1`로 설정하고 OpenRouter API 키를 사용하세요.
- **LM Studio:** `api_base`를 로컬 서버 URL(예: `http://localhost:1234/v1`)로 설정하세요.
- **Azure OpenAI:** Azure 전용 API base를 사용하고 deployment 이름을 모델로 사용하세요.
- **커스텀 헤더:** 일부 엔드포인트는 추가 헤더가 필요합니다. 해당 문서를 참조하세요.

> 💡 **프로바이더별 실전 설정 예시**
> 
> **OpenRouter 사용** (추천: 다양한 모델 접근):
> ```python
> from llama_index.llms.openai_like import OpenAILike
> import os
> 
> llm = OpenAILike(
>     model="anthropic/claude-3.5-sonnet",  # 슬래시 형식
>     api_base="https://openrouter.ai/api/v1",
>     api_key=os.getenv("OPENROUTER_API_KEY"),
>     is_chat_model=True
> )
> 
> # OpenRouter 장점:
> # - 100개 이상 모델을 하나의 키로
> # - 가격 비교 가능
> # - 무료 모델도 제공 (`:free` 접미사)
> ```
> 
> **LM Studio 로컬 실행**:
> ```python
> # 1. LM Studio 앱에서 "Local Server" 시작
> # 2. 모델 로드 (예: llama-3-8b)
> # 3. 코드 실행
> 
> llm = OpenAILike(
>     model="llama-3-8b",  # LM Studio에서 로드한 모델명
>     api_base="http://localhost:1234/v1",
>     api_key="not-needed",  # 로컬은 키 불필요
>     is_chat_model=True
> )
> 
> # 장점: 무료, 오프라인, 프라이버시
> # 단점: 느림, 사양 필요
> ```
> 
> **Azure OpenAI** (엔터프라이즈):
> ```python
> # Azure Portal에서 리소스 생성 필요
> llm = OpenAILike(
>     model="my-gpt4-deployment",  # 직접 설정한 deployment 이름
>     api_base="https://my-resource.openai.azure.com/",
>     api_key=os.getenv("AZURE_OPENAI_KEY"),
>     is_chat_model=True,
>     # Azure 전용 설정
>     api_type="azure",
>     api_version="2023-05-15"
> )
> ```
> 
> **커스텀 헤더 필요 시**:
> ```python
> # 일부 프록시 서비스는 추가 헤더 필요
> llm = OpenAILike(
>     model="gpt-4",
>     api_base="https://custom-proxy.com/v1",
>     api_key=os.getenv("API_KEY"),
>     is_chat_model=True,
>     additional_kwargs={
>         "headers": {
>             "HTTP-Referer": "https://myapp.com",
>             "X-Title": "My App"
>         }
>     }
> )
> ```
> 
> **환경 변수로 API 키 관리** (권장):
> ```python
> # .env 파일 생성
> """
> OPENAI_API_KEY=sk-...
> OPENROUTER_API_KEY=sk-or-...
> AZURE_OPENAI_KEY=...
> """
> 
> # Python 코드
> from dotenv import load_dotenv
> import os
> 
> load_dotenv()
> 
> llm = OpenAILike(
>     model="gpt-4",
>     api_key=os.getenv("OPENAI_API_KEY"),  # 안전하게 로드
>     is_chat_model=True
> )
> ```

## 4. 문제 해결

- **인증 오류:** API 키와 엔드포인트를 다시 확인하세요.
- **모델을 찾을 수 없음:** 모델 이름이 프로바이더가 지원하는 것과 일치하는지 확인하세요.
- **연결 오류:** 로컬 서버를 사용하는 경우 실행 중이고 접근 가능한지 확인하세요.
- **비전:** 대부분의 OpenAI-like 엔드포인트는 이미지 입력을 지원하지 않습니다. 모델이 지원하는 것을 알지 못하는 한 `vision=False`로 설정하세요.

> 🔧 **구체적인 문제 해결 방법**
> 
> **1. "Authentication failed" / "Invalid API key"**
> ```python
> # 디버깅 체크리스트:
> import os
> 
> # 1) API 키 확인
> print(f"API Key: {os.getenv('OPENAI_API_KEY')[:10]}...")  # 앞 10자만
> 
> # 2) 키 형식 확인
> # OpenAI: sk-...로 시작
> # OpenRouter: sk-or-...로 시작
> # Azure: 32자 영숫자
> 
> # 3) 환경 변수 재설정
> export OPENAI_API_KEY="your-actual-key"
> 
> # 4) 직접 전달 (테스트용)
> llm = OpenAILike(
>     api_key="sk-...",  # 하드코딩 (테스트만)
>     ...
> )
> ```
> 
> **2. "Model not found" / "Invalid model"**
> ```python
> # 프로바이더별 모델명 형식:
> 
> # OpenAI (공식)
> valid_openai = ["gpt-4o", "gpt-4", "gpt-3.5-turbo"]
> 
> # OpenRouter (슬래시 필수)
> valid_openrouter = [
>     "openai/gpt-4",
>     "anthropic/claude-3.5-sonnet",
>     "meta-llama/llama-3-70b"
> ]
> 
> # Azure (deployment 이름)
> # Azure Portal에서 설정한 이름 그대로 사용
> 
> # LM Studio (로드한 모델명)
> # LM Studio UI에서 확인
> ```
> 
> **3. "Connection refused" / "Cannot connect"**
> ```sh
> # 로컬 서버(LM Studio 등) 확인:
> 
> # 1) 서버 실행 확인
> curl http://localhost:1234/v1/models
> 
> # 2) 포트 충돌 확인
> # LM Studio 기본 포트: 1234
> # Ollama 기본 포트: 11434
> 
> # 3) 방화벽 확인
> # Windows: 제어판 → 방화벽
> # Mac: 시스템 환경설정 → 보안
> ```
> 
> **4. Vision 관련 오류**
> ```python
> # 대부분의 OpenAI-like 서비스는 vision 미지원
> 
> # Vision 지원 모델:
> vision_supported = [
>     "gpt-4o",           # OpenAI
>     "gpt-4-vision",     # OpenAI
>     "claude-3-opus",    # Anthropic (OpenRouter 통해)
>     "gemini-pro-vision" # Google (OpenRouter 통해)
> ]
> 
> # 확실하지 않으면 항상 vision=False
> agent = DroidAgent(
>     goal="...",
>     llm=llm,
>     tools=tools,
>     vision=False  # 안전한 기본값
> )
> ```
> 
> **5. 느린 응답 / 타임아웃**
> ```python
> # OpenRouter나 프록시 사용 시 느릴 수 있음
> 
> llm = OpenAILike(
>     model="gpt-4",
>     api_base="https://openrouter.ai/api/v1",
>     api_key=os.getenv("OPENROUTER_API_KEY"),
>     is_chat_model=True,
>     timeout=120,  # 타임아웃 증가 (초)
>     max_retries=3  # 재시도 횟수
> )
> ```
> 
> **6. "Rate limit exceeded" (요청 제한)**
> ```python
> # 해결 방법 1: 요청 간 대기
> import asyncio
> 
> for task in tasks:
>     result = await agent.run()
>     await asyncio.sleep(1)  # 1초 대기
> 
> # 해결 방법 2: 더 저렴한 모델 사용
> llm = OpenAILike(
>     model="gpt-3.5-turbo",  # gpt-4보다 제한 여유로움
>     ...
> )
> 
> # 해결 방법 3: 여러 키 로테이션
> keys = [
>     os.getenv("OPENAI_KEY_1"),
>     os.getenv("OPENAI_KEY_2")
> ]
> current_key = keys[request_count % len(keys)]
> ```

## 5. 더 읽어보기

- [OpenRouter 문서](https://openrouter.ai/docs)
- [LM Studio 문서](https://lmstudio.ai/docs)
- [llama-index OpenAI Like LLM 문서](https://docs.llamaindex.ai/en/stable/api_reference/llms/openai_like/)
> 📚 **추가 학습 자료 및 팁**
> 
> **공식 문서**:
> - [OpenAI API 레퍼런스](https://platform.openai.com/docs/api-reference)
> - [Azure OpenAI 가이드](https://learn.microsoft.com/azure/ai-services/openai/)
> - [OpenRouter 모델 목록](https://openrouter.ai/models) - 가격 비교 포함
> 
> **비용 최적화 전략**:
> ```python
> # 1. 간단한 작업: 저렴한 모델
> simple_llm = OpenAILike(model="gpt-3.5-turbo")
> 
> # 2. 복잡한 작업: 고급 모델
> complex_llm = OpenAILike(model="gpt-4o")
> 
> # 3. 조건부 선택
> llm = simple_llm if len(task) < 100 else complex_llm
> ```
> 
> **멀티 프로바이더 전략**:
> ```python
> # 메인: OpenAI (빠르고 안정적)
> # 백업: OpenRouter (메인 장애 시)
> 
> try:
>     llm = OpenAILike(
>         model="gpt-4",
>         api_key=os.getenv("OPENAI_API_KEY")
>     )
>     result = await agent.run()
> except Exception as e:
>     print(f"OpenAI 실패: {e}, OpenRouter로 전환")
>     llm = OpenAILike(
>         model="openai/gpt-4",
>         api_base="https://openrouter.ai/api/v1",
>         api_key=os.getenv("OPENROUTER_API_KEY")
>     )
>     result = await agent.run()
> ```

---

이 설정을 통해 Droidrun과 함께 Android 자동화 및 에이전트 기반 워크플로에 OpenAI 호환 LLM을 사용할 수 있습니다!